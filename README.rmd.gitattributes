# Question: Which Catcher performs the best at catching pitches in the dataset?

# Packages needed

install.packages("dplyr")
install.packages("randomForest")
install.packages("neuralnet")
install.packages("rpart")
install.packages("tidyverse")
install.packages("caret")
install.packages("gbm")
install.packages("xgboost")
install.packages("ggplot2")

library(dplyr)
library(randomForest)
library(neuralnet)
library(rpart)
library(tidyverse)
library(caret)
library(gbm)
library(xgboost)
library(ggplot2)


# Filtering Data

# The below code subset out attributes and rows not beneficial to the creation of the model to maximize accuracy in the following steps.

catcherframe <- filter(catcherframe, pitcheventtype == c(“called_strike”, “ball”)) 
catcherframe <- filter(catcherframe, !is.na(ump_hp)) 
catcherframe <- filter(catcherframe, catcherframe$balls != 4)
catcherframe <- select(catcherframe, list = -c(pitcherhand, batside, pitchtype, pitcheventtype, bluejaysgameid)) 

# Training Data

#The below splits the data set based off a random selection on a 70:30 ratio. This allows for a nonbiased selection to allow for true results when predicted.

set.seed(16532)

train <- sample(nrow(catcherframe), 0.7*nrow(catcherframe), replace = FALSE) 
Catcher_Train <- catcherframe[train,]
Catcher_Test <- catcherframe[-train,]

# Random Forest

# Initial creation of the model from the attribute of the “calledstrike” on the rest of the attrributes

model <- randomForest(calledstrike ~., data = Catcher_Train, importance = TRUE, ntrees = 1000) predCatcher_Train <- predict(model, Catcher_Train, type = "class") 
table(predCatcher_Train, Catcher_Train$catcherid)

# You can check the importance of attributes to the above model to understand what attributes affect the dependent variable that way you can be assured of a more accurate model.

importance(model)

# Recreating the model based off the importance function

model_1 <- randomForest(calledstrike ~ ball + plate_x + plate_z + relspeed + vbreak + hbreak + strikes + balls, data = Catcher_Train, importance = TRUE, ntrees = 1000) 

# Predicting the accuracy of the model

predCatcher_Train <- predict(model_1, Catcher_Train, type = “class”) 

# Checking the Classification of the attribute in question

class(catcherframe$calledstrike)
catcherframe$calledstrike <- as.factor(catcherframecalledstrike)

model1<-randomForest(calledstrike ~ ball+plate_x+plate_z+relspeed+vbreak+hbreak+strikes+balls,data=Catcher_T rain,importance=TRUE,ntrees=1000)

class(catcherframe$calledstrike) 

# ReTrain Data

# Retraining the data for maximum accuracy

train <- sample(nrow(catcherframe), 0.7*nrow(catcherframe), replace = FALSE) 
Catcher_Train <- catcherframe[train,] 
Catcher_Test <- catcherframe[-train,] 

# Back to Random Forest

# Rerunning the random forest model

model_1 <- randomForest(calledstrike ~ ball + plate_x + plate_z + relspeed + vbreak + hbreak + strikes + balls, data = Catcher_Train, importance = TRUE, ntrees = 1000) 

# Predicting both on Train and Test data

predCatcher_Train <- predict(model_1, Catcher_Train, type = “class”) 
predCatcher_Test <- predict(model_1, Catcher_Test, type = “class”) 

# Binding the predicted values attribute to a new dataset with the Train data

catcherframe_new <- cbind(Catcher_Train, predCatcher_Train) 

# Converting the new predicted attribute to numeric. The "-1" was to change the outcome from 1, 2 to 0, 1.

catcherframe_new$predCatcher_T rain<-as.numeric(catcherframe_new$predCatcher_Train) - 1 

# Finalizing the second model and predict on both the train and test data sets. Then binding the Train and prediction data into a main data set as a separate attribute


# Graph RandomForest

# Below lines of code is run to predict the ROC curve for the Random Forest graph

pred_ROC_Curve_Rf <- predict(model_1, Catcher_Test, type = "prob")
pretty_colors <- c("blue", "red")

classes <- levels(Catcher_Test$calledstrike)
for (i in 1:3)
+ {
+     true_values <- ifelse(Catcher_Test[,5]==classes[i],1,0)
+         pred_RF <- prediction(pred_ROC_Curve_Rf[,i],true_values)
+     perf_RF <- performance(pred_RF, "tpr", "fpr")
+     if (i==1)
+     {
+         plot(perf_RF,main="ROC Curve",col=pretty_colors[i]) 
+     }
+     else
+     {
+         plot(perf_RF,main="ROC Curve",col=pretty_colors[i],add=TRUE) 
+     }
+     # Calculate the AUC and print it to screen
+     auc_perf <- performance(pred_RF, measure = "auc")
+     print(auc_perf@y.values)
+ }
 

 
# Neural Net

# Normalizing the data set to allow for the neural net model to run

Catcher_Train_Scaled <- scale(Catcher_Train)

# Creating the Neural Net Model

nn_model <- neuralnet(calledstrike ~ ball + plate_x + plate_z + relspeed + vbreak + hbreak + strikes + balls, data = Catcher_Train_Scaled, hidden = c(5,3), act.fct = “logistic”, linear.output = FALSE)

# Using the predict() to predict outcomes based off the normalized data set based off the model.

nn_predict <- predict(nn_model, Catcher_Train_Scaled)
View(nn_predict)
summary(nn_predict) 

# You can then attach and create a seperate attribute onto the same data set I attached the Random Forest model to show the differences. I do this for all models created and ran.

catcherframe_new <- cbind(catcherframe_new, nn_predict)
I created a Neural Network model based off the same parameters from the Random Forest model above. Once created I predicted the outcome based off the Train data set. Noticing that it did not work I had to normalize the data set with the scale() function and predict based off the normalized data set. I then bound the prediction data into the main data set as a separate output attribute 

# Creating the change graph based off the Neural Net model

# Neural Net Graph

pred_ROC_Curve_NN <- predict(nn_model, Catcher_Test, type = "prob")

# Creating the Decision Tree model using the rpart package.

catcherframe_DT <- rpart(calledstrike ~ ball + plate_x + plate_z + relspeed + vbreak + hbreak + strikes + balls, data = Catcher_Train, method = “class”) DT_predict <- predict(catcherframe_DT,Catcher_Train)
DT_predict <- predict(catcherframe_DT, Catcher_Train)
catcherframe_new <- cbind(catcherframe_new, DT_predict) 

# Using the rpart.plot command you can create the chart to show the flow of decision making the machine goes through.

rpart.plot(catcherframe_DT)

# Decision Tree Matrix

# You can create a matrix based off the Decision Tree model to show the accuracy of the model. First you have to convert the predicted values into a data frame

DT_predict_df <- as.data.frame(DT_predict)

# You then table the results to show 

DT_table <- table(Catcher_Train$calledstrike, DT_predict_df[[2]])

# The matrix below shows the model’s accuracy based on a true positive, true negative, false positive, false negative matrix. The “0” represent the “FALSE” outcomes and the “1” represents the “TRUE” outcomes. As you can see above the model was extremely accurate. True Negatives equaled to 36073 while True Positives equaled 17570. Both False positive and negatives came out to 0!

Predicted   
        0            1
  0    36073         0
  1	0          17570

# Gradient Boosting

# you can create the Gradient Boosting model with the line of code that follows. The number of trees is key because you do not want to voer fit your model which we will see at the graph

catcherframe_GBM <- gbm(calledstrike ~ ball + plate_x + plate_z + relspeed + hbreak + vbreak + strikes + balls, data = Catcher_Train, distribution = "gaussian", n.trees = 1000, shrinkage = 0.01, interaction.depth = 5, cv.folds = 2, n.cores = NULL, verbose = FALSE)

# To complete the prediction portion you will have to decide the amount of trees you would like to base the prediction of the model.

n.trees <- seq(from = 100, to = 500, by = 100)

# You then predict the model off the stated amount of trees and bind it to the same data set as the other three models to show the discrepency if any.

GBM_predict <- predict(catcherframe_GBM, Catcher_Train, n.trees = n.trees)
catcherframe_new <- cbind(catcherframe_new, GBM_predict)

 
# GBM Plot

# The graph below shows the accuracy between amounts of trees based off the Gradient Boosting model created. 
# Using the gbm.perf() you can create the graph to show the accuracy
# This graph shows that around 400 trees the cross-validation error decreased and essentially flattens out. 
# Therefore within the model the amount of trees above 500 or so would have been suffice to accurately predict called strikes

gbm.perf(catcherframe_GBM, method = "cv")
 
# XGB

# To properly perform an Extremem Gradient Boosting model you will have to retrain the data to 4 sections as shown below.

Catcher_Train_xgb_x <- xgb.DMatrix(as.matrix(Catcher_Train %>% select(-calledstrike)))
Catcher_Train_xgb_y <- Catcher_Train$calledstrike
Catcher_Test_xgb_x <- xgb.DMatrix(as.matrix(Catcher_Test %>% select(-calledstrike)))
Catcher_Test_xgb_y <- Catcher_Test$calledstrike

# You then have to create a control to specify the cross validation and number of folds within the model.

TrainControl <- trainControl( method = "repeatedcv", number = 3, repeats = 2)

# Then create and predict the model based on the Train data set.

XGB_model <- train(Catcher_Train_xgb_x, Catcher_Train_xgb_y, method = "xgbTree", trControl = TrainControl, verbose = FALSE)

XGB_predict <- predict(XGB_model, Catcher_Train)
XGB_predict_Test <- predict(XGB_model, Catcher_Test_xgb_x)

catcherframe_new <- cbind(catcherframe_new, XGB_predict)

# XGB Plot

# Because you already predicted off the train data set you will have to do the same to create the accuracy graph on the test data.

XGB_predict_Test <- predict(XGB_model, Catcher_Test_xgb_x)

# Then create a data frame with both the test and train data from the prediction on the test and the Test data.

XGBplot_data <- as.data.frame(cbind(predicted = XGB_predict_Test, observed = Catcher_Test_xgb_y)

# Using ggplot() you can create the accuracy graph based off the test data frame you created above. Be sure to specify the x an y portions of the graph

ggplot(XGBplot_data, aes(x = predicted, y = observed)) + geom_point(color = "darkred", alpha = 0.5) + geom_smooth(method = lm) + ggtitle("Extreme Gradient Boosting: Prediction vs Test Data") + xlab("Observed Output") + ylab("Called Strike Predicted")

# Finishing Touches

# Using the dplyr package you can now remove attributes that are not conducive to the finished product

catcherframe_new_1 <- select(catcherframe_new, by = -c(calledstrike, ball, takes)) 

# You then use the aggregate function to summarize the scores per catcher to find out which catcher has the highest score.

catcherframe_new_2 <- aggregate(catcherframe_new_1, by = list(catcherframe_new$catcherid), FUN = sum) View(catcherframe_new_2) 

# For easier reading I renamed an attribute but this is completely optional

catcherframe_new_2 <- rename(catcherframe_new_2, predCatcherRF = predCatcher_Train)